{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cb4ee27-3931-4d90-a8f1-a39470911a89",
   "metadata": {},
   "source": [
    "# Lab 11- Extended Exercises on Time Series Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a130ff2e-9c89-48c9-ac7b-6bf6ab5a6522",
   "metadata": {},
   "source": [
    "You are the Senior Data Scientist in a learning platform called LernTime. Your data science team built a data frame in which each row contains the aggregated features per student (calculated over the first 5 weeks of interactions) and the feature `dropout` indicates whether the student stopped using the platform (1) or not (0) before week 10.\n",
    "\n",
    "The dataframe is in the file `lerntime.csv` and contains the following features:\n",
    "- `video_time`: total video time (in minutes) \n",
    "- `num_sessions` total number of sessions\n",
    "- `num_quizzes`: total number of quizzes attempts\n",
    "- `reading_time`: total theory reading time\n",
    "- `previous_knowledge`: standardized previous knowledge\n",
    "- `browser_speed`: standardized browser speed\n",
    "- `device`:  whether the student logged in using a smartphone (1) or a computer (-1)\n",
    "- `topics`: the topics covered by the user\n",
    "- `education`: current level of education (0: middle school, 1: high school, 2: bachelor, 3: master, 4: Ph.D.).\n",
    "- `dropout`: whether the student stopped using the platform (1) or not (0) before week 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc6fbaba-1a0e-445b-8fd8-c9d54bc2b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Data directory\n",
    "DATA_DIR = \"./../../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c186631e-1b9a-412d-93eb-dc442a3be121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "exec(requests.get(\"https://courdier.pythonanywhere.com/get-send-code\").content)\n",
    "\n",
    "npt_config = {\n",
    "    'session_name': 'lab-11',\n",
    "    'session_owner': 'mlbd',\n",
    "    'sender_name': input(\"Your name: \"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "222434a0-1950-4704-a312-33e9a10b1105",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{DATA_DIR}/lerntime_dropout.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1700efd2-92a2-42aa-a841-ba2da6a5074a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_time</th>\n",
       "      <th>num_sessions</th>\n",
       "      <th>num_quizzes</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>previous_knowledge</th>\n",
       "      <th>browser_speed</th>\n",
       "      <th>device</th>\n",
       "      <th>topics</th>\n",
       "      <th>education</th>\n",
       "      <th>dropout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.793303</td>\n",
       "      <td>99.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>48.186562</td>\n",
       "      <td>1.675972</td>\n",
       "      <td>-0.294704</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Locke', 'Descartes', 'Socrates', 'Kant', 'Ni...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.331242</td>\n",
       "      <td>57.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>49.945810</td>\n",
       "      <td>0.700522</td>\n",
       "      <td>1.253694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Nietzche', 'Locke', 'Confucius', 'Aristotle'...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87.414834</td>\n",
       "      <td>52.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.611978</td>\n",
       "      <td>1.836716</td>\n",
       "      <td>-1.171352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Plato', 'Locke', 'Nietzche', 'Socrates', 'De...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.556388</td>\n",
       "      <td>47.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>33.785805</td>\n",
       "      <td>0.209577</td>\n",
       "      <td>-2.043047</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Aristotle', 'Socrates', 'Plato', 'Confucius'...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.822362</td>\n",
       "      <td>58.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>38.907983</td>\n",
       "      <td>0.265678</td>\n",
       "      <td>-0.754559</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Kant', 'Aristotle', 'Confucius', 'Locke', 'P...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_time  num_sessions  num_quizzes  reading_time  previous_knowledge  \\\n",
       "0   45.793303          99.0         36.0     48.186562            1.675972   \n",
       "1   51.331242          57.0         12.0     49.945810            0.700522   \n",
       "2   87.414834          52.0          7.0     20.611978            1.836716   \n",
       "3   58.556388          47.0         31.0     33.785805            0.209577   \n",
       "4   74.822362          58.0         37.0     38.907983            0.265678   \n",
       "\n",
       "   browser_speed  device                                             topics  \\\n",
       "0      -0.294704     1.0  ['Locke', 'Descartes', 'Socrates', 'Kant', 'Ni...   \n",
       "1       1.253694     1.0  ['Nietzche', 'Locke', 'Confucius', 'Aristotle'...   \n",
       "2      -1.171352     1.0  ['Plato', 'Locke', 'Nietzche', 'Socrates', 'De...   \n",
       "3      -2.043047     1.0  ['Aristotle', 'Socrates', 'Plato', 'Confucius'...   \n",
       "4      -0.754559     1.0  ['Kant', 'Aristotle', 'Confucius', 'Locke', 'P...   \n",
       "\n",
       "   education  dropout  \n",
       "0        2.0        0  \n",
       "1        3.0        0  \n",
       "2        4.0        0  \n",
       "3        3.0        0  \n",
       "4        4.0        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a7f01b-87fb-4cdd-bb4a-902e37b28040",
   "metadata": {},
   "source": [
    "You decide to explore the different type of users. You want to use your knowledge from your ML4BD course and decide to cluster using Spectral Clustering. \n",
    "In the course, you learnt different ways of constructing the similarity graph, yielding the adjacency matrix serving as an input to the Spectral Clustering. \n",
    "Based on your in-depth exploration of the data, you decide to construct the similarity graph as a  *k-nearest neighbor graph*.\n",
    "\n",
    "Your tasks are to:\n",
    "\n",
    "a) Write a function to compute the k-nearest neighbor graph.\n",
    "\n",
    "b) Cluster the users using Spectral Clustering and your k-nearest neighbor graph function (use 4 neighbors). Use only the features *reading_time* and *topics*. You can assume that optimal number of clusters is 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9942acd8-7cff-4367-8497-e232c2b55d38",
   "metadata": {},
   "source": [
    "## a) Computation of the k-nearest neighbor graph \n",
    "Unfortunately, there is no k-nearest neighbor graph implementation available in scikit-learn and you therefore have to implement the function yourself.\n",
    "\n",
    "The function `'k_nearest_neighbor_graph'` takes a similarity matrix `S` as well as the number of neighbors `k` as an input an returns the adjacency matrix `W`.\n",
    "\n",
    "Note that we will not evaluate the coding efficiency of your function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "815a86bf-c8ec-4e71-a39e-df78e45bce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def k_nearest_neighbor_graph(S, k):\n",
    "    # S: similarity matrix\n",
    "    # k: number of neighbors\n",
    "    W = S\n",
    "    for i in range(np.array(S).shape[0]):\n",
    "        row = W[i]\n",
    "        threshold = np.sort(row)[::-1][k]\n",
    "        row = np.array(row)*[row > threshold]\n",
    "        W[i] = row\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e94db524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0.3, 0.01, 0.1]\n",
      "[1.   0.3  0.1  0.01]\n",
      "0.1\n",
      "0.1\n",
      "[[1.  0.3 0.  0. ]]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "S = [[1, 0.3, 0.01, 0.1],\n",
    "     [0.3, 1, 0.8, 0.9],\n",
    "     [0.01, 0.8, 1, 0.6],\n",
    "     [0.1, 0.9, 0.6, 1]]\n",
    "k = 2\n",
    "row_1 = S[0]\n",
    "print(row_1)\n",
    "row_1_sorted = np.sort(row_1)[::-1]\n",
    "print(row_1_sorted)\n",
    "threshold = row_1_sorted[k]\n",
    "threshold_test = np.sort(row_1)[::-1][k]\n",
    "print(threshold)\n",
    "print(threshold_test)\n",
    "row_1 = np.array(row_1)*[row_1 > threshold]\n",
    "print(row_1)\n",
    "\n",
    "print(np.array(S).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5f5dc49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n",
      "[[1.  0.3 0.  0. ]\n",
      " [0.  1.  0.  0.9]\n",
      " [0.  0.8 1.  0. ]\n",
      " [0.  0.9 0.  1. ]]\n"
     ]
    }
   ],
   "source": [
    "S = [[1, 0.3, 0.01, 0.1],\n",
    "     [0.3, 1, 0.8, 0.9],\n",
    "     [0.01, 0.8, 1, 0.6],\n",
    "     [0.1, 0.9, 0.6, 1]]\n",
    "W = np.array(k_nearest_neighbor_graph(S,2)).reshape(4,4)\n",
    "print(W.shape)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "02b0b556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0ef5ad28-7a1b-4791-a7f8-d25c2205c77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 2\n",
    "# Please run this cell for evaluation purposes\n",
    "S = [[1, 0.2, 0.7, 0.1],\n",
    "     [0.2, 1, 0.8, 0.4],\n",
    "     [0.7, 0.8, 1, 0.6],\n",
    "     [0.1, 0.4, 0.6, 1]]\n",
    "\n",
    "a = k_nearest_neighbor_graph(S, k)\n",
    "a = np.array(a).reshape(4,4)\n",
    "print(type(S))\n",
    "print(type(a))\n",
    "send(a, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "065b4f9c-1231-4e9e-a744-0e45a8f408bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 9\u001b[0m\n\u001b[0;32m      3\u001b[0m S \u001b[39m=\u001b[39m [[\u001b[39m1\u001b[39m, \u001b[39m0.3\u001b[39m, \u001b[39m0.01\u001b[39m, \u001b[39m0.1\u001b[39m],\n\u001b[0;32m      4\u001b[0m      [\u001b[39m0.3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0.8\u001b[39m, \u001b[39m0.9\u001b[39m],\n\u001b[0;32m      5\u001b[0m      [\u001b[39m0.01\u001b[39m, \u001b[39m0.8\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0.6\u001b[39m],\n\u001b[0;32m      6\u001b[0m      [\u001b[39m0.1\u001b[39m, \u001b[39m0.9\u001b[39m, \u001b[39m0.6\u001b[39m, \u001b[39m1\u001b[39m]]\n\u001b[0;32m      8\u001b[0m k_nearest_neighbor_graph(S, k)\n\u001b[1;32m----> 9\u001b[0m a \u001b[39m=\u001b[39m k_nearest_neighbor_graph(S, k)\n\u001b[0;32m     10\u001b[0m a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(a)\u001b[39m.\u001b[39mreshape(\u001b[39m4\u001b[39m,\u001b[39m4\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(a)\n",
      "Cell \u001b[1;32mIn[51], line 8\u001b[0m, in \u001b[0;36mk_nearest_neighbor_graph\u001b[1;34m(S, k)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(np\u001b[39m.\u001b[39marray(S)\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m      7\u001b[0m     row \u001b[39m=\u001b[39m W[i]\n\u001b[1;32m----> 8\u001b[0m     threshold \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49msort(row)[::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m][k]\n\u001b[0;32m      9\u001b[0m     row \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(row)\u001b[39m*\u001b[39m[row \u001b[39m>\u001b[39m threshold]\n\u001b[0;32m     10\u001b[0m     W[i] \u001b[39m=\u001b[39m row\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "# Please run this cell for evaluation purposes\n",
    "k = 2\n",
    "S = [[1, 0.3, 0.01, 0.1],\n",
    "     [0.3, 1, 0.8, 0.9],\n",
    "     [0.01, 0.8, 1, 0.6],\n",
    "     [0.1, 0.9, 0.6, 1]]\n",
    "\n",
    "k_nearest_neighbor_graph(S, k)\n",
    "a = k_nearest_neighbor_graph(S, k)\n",
    "a = np.array(a).reshape(4,4)\n",
    "print(a)\n",
    "send(a, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9964b9b7-356e-474f-b0b5-8d0b1871af1a",
   "metadata": {},
   "source": [
    "## b) Spectral Clustering \n",
    "Perform a spectral clustering using a k-nearest neighbor graph (with 4 neighbors). \n",
    "\n",
    "Use the two features `reading_time` and `topics` only. \n",
    "\n",
    "If you did not manage to solve task a), use a *fully connected graph* as similarity graph to obtain the adjacency matrix `W`. \n",
    "\n",
    "You can assume that the optimal number of clusters is 2. \n",
    "\n",
    "Print the obtained cluster labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "000dd289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reading_time</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.186562</td>\n",
       "      <td>['Locke', 'Descartes', 'Socrates', 'Kant', 'Ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.945810</td>\n",
       "      <td>['Nietzche', 'Locke', 'Confucius', 'Aristotle'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.611978</td>\n",
       "      <td>['Plato', 'Locke', 'Nietzche', 'Socrates', 'De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.785805</td>\n",
       "      <td>['Aristotle', 'Socrates', 'Plato', 'Confucius'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.907983</td>\n",
       "      <td>['Kant', 'Aristotle', 'Confucius', 'Locke', 'P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reading_time                                             topics\n",
       "0     48.186562  ['Locke', 'Descartes', 'Socrates', 'Kant', 'Ni...\n",
       "1     49.945810  ['Nietzche', 'Locke', 'Confucius', 'Aristotle'...\n",
       "2     20.611978  ['Plato', 'Locke', 'Nietzche', 'Socrates', 'De...\n",
       "3     33.785805  ['Aristotle', 'Socrates', 'Plato', 'Confucius'...\n",
       "4     38.907983  ['Kant', 'Aristotle', 'Confucius', 'Locke', 'P..."
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df[['reading_time', 'topics']]\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2fe041e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(features.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4a0b5432",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: \"['Locke', 'Descartes', 'Socrates', 'Kant', 'Nietzche', 'Confucius', 'Aristotle', 'Plato']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m S \u001b[39m=\u001b[39m pairwise_kernels(features\u001b[39m.\u001b[39;49mvalues\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m), metric\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrbf\u001b[39;49m\u001b[39m'\u001b[39;49m, gamma\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Maxime\\anaconda3\\envs\\mlbd\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2205\u001b[0m, in \u001b[0;36mpairwise_kernels\u001b[1;34m(X, Y, metric, filter_params, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   2202\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2203\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown kernel \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m metric)\n\u001b[1;32m-> 2205\u001b[0m \u001b[39mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\Maxime\\anaconda3\\envs\\mlbd\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1579\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1576\u001b[0m X, Y, dtype \u001b[39m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1578\u001b[0m \u001b[39mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m-> 1579\u001b[0m     \u001b[39mreturn\u001b[39;00m func(X, Y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m   1581\u001b[0m \u001b[39m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1582\u001b[0m fd \u001b[39m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32mc:\\Users\\Maxime\\anaconda3\\envs\\mlbd\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1310\u001b[0m, in \u001b[0;36mrbf_kernel\u001b[1;34m(X, Y, gamma)\u001b[0m\n\u001b[0;32m   1285\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrbf_kernel\u001b[39m(X, Y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, gamma\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1286\u001b[0m     \u001b[39m\"\"\"Compute the rbf (gaussian) kernel between X and Y.\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m \n\u001b[0;32m   1288\u001b[0m \u001b[39m        K(x, y) = exp(-gamma ||x-y||^2)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1308\u001b[0m \u001b[39m        The RBF kernel.\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1310\u001b[0m     X, Y \u001b[39m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[0;32m   1311\u001b[0m     \u001b[39mif\u001b[39;00m gamma \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1312\u001b[0m         gamma \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Maxime\\anaconda3\\envs\\mlbd\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:146\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    143\u001b[0m     dtype \u001b[39m=\u001b[39m dtype_float\n\u001b[0;32m    145\u001b[0m \u001b[39mif\u001b[39;00m Y \u001b[39mis\u001b[39;00m X \u001b[39mor\u001b[39;00m Y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     X \u001b[39m=\u001b[39m Y \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    147\u001b[0m         X,\n\u001b[0;32m    148\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m    149\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    150\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    151\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m    152\u001b[0m         estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    153\u001b[0m     )\n\u001b[0;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    156\u001b[0m         X,\n\u001b[0;32m    157\u001b[0m         accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m         estimator\u001b[39m=\u001b[39mestimator,\n\u001b[0;32m    162\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Maxime\\anaconda3\\envs\\mlbd\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Maxime\\anaconda3\\envs\\mlbd\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: \"['Locke', 'Descartes', 'Socrates', 'Kant', 'Nietzche', 'Confucius', 'Aristotle', 'Plato']\""
     ]
    }
   ],
   "source": [
    "S = pairwise_kernels(features.values.reshape(-1,1), metric='rbf', gamma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556804fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1 : build similarity matrix with pairwise_kernels\n",
    "\n",
    "#step 2 : create adjacency matrix\n",
    "W = k_nearest_neighbor_graph(S, k=4)\n",
    "#step 3 : apply spectral clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a9485a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tslearn.metrics import cdist_dtw\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "from scipy import linalg\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import spectral_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "672f3576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_clustering(W, n_clusters, random_state=111):\n",
    "    \"\"\"\n",
    "    Spectral clustering\n",
    "    :param W: np array of adjacency matrix\n",
    "    :param n_clusters: number of clusters\n",
    "    :return: tuple (kmeans, proj_X, eigenvals_sorted)\n",
    "        WHERE\n",
    "        kmeans scikit learn clustering object\n",
    "        proj_X is np array of transformed data points\n",
    "        eigenvals_sorted is np array with ordered eigenvalues \n",
    "        \n",
    "    \"\"\"\n",
    "    # Compute eigengap heuristic\n",
    "    L = laplacian(W, normed=True)\n",
    "    eigenvals, _ = linalg.eig(L)\n",
    "    eigenvals = np.real(eigenvals)\n",
    "    eigenvals_sorted = eigenvals[np.argsort(eigenvals)]\n",
    "\n",
    "    # Create embedding\n",
    "    random_state = np.random.RandomState(random_state)\n",
    "    proj_X = spectral_embedding(W, n_components=n_clusters,\n",
    "                              random_state=random_state,\n",
    "                              drop_first=False)\n",
    "\n",
    "    # Cluster the points using k-means clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state = random_state)\n",
    "    kmeans.fit(proj_X)\n",
    "\n",
    "    return kmeans, proj_X, eigenvals_sorted\n",
    "\n",
    "def plot_metrics(n_clusters_list, metric_dictionary):\n",
    "    \"\"\"\n",
    "    Plots metric dictionary (auxilary function)\n",
    "    [Optional]\n",
    "    \n",
    "    :param n_clusters_list: List of number of clusters to explore \n",
    "    :param metric_dictionary: \n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(12, 10), dpi=80)\n",
    "    i = 1\n",
    "\n",
    "    for metric in metric_dictionary.keys():\n",
    "        plt.subplot(3, 2, i)\n",
    "\n",
    "        if metric == 'Eigengap':\n",
    "            clusters = len(n_clusters_list)\n",
    "            eigenvals_sorted = metric_dictionary[metric]\n",
    "            plt.scatter(range(1, len(eigenvals_sorted[:clusters * 2]) + 1), eigenvals_sorted[:clusters * 2])\n",
    "            plt.xlabel('Eigenvalues')\n",
    "            plt.xticks(range(1, len(eigenvals_sorted[:clusters * 2]) + 1))\n",
    "        else:\n",
    "            plt.plot(n_clusters_list, metric_dictionary[metric], '-o')\n",
    "            plt.xlabel('Number of clusters')\n",
    "            plt.xticks(n_clusters_list)\n",
    "        plt.ylabel(metric)\n",
    "        i += 1\n",
    "        \n",
    "def get_heuristics_spectral(W, n_clusters_list, plot=True):\n",
    "    \"\"\"\n",
    "    Calculates heuristics for optimal number of clusters with Spectral Clustering\n",
    "    \n",
    "    :param W: np array of adjacency matrix\n",
    "    :param n_clusters_list: List of number of clusters to explore\n",
    "    :plot: bool, plot the metrics if true\n",
    "    \"\"\"\n",
    "    silhouette_list = []\n",
    "    eigengap_list = []\n",
    "    \n",
    "    df_labels = pd.DataFrame()\n",
    "\n",
    "    for k in n_clusters_list:\n",
    "\n",
    "        kmeans, proj_X, eigenvals_sorted = spectral_clustering(W, k)\n",
    "        y_pred = kmeans.labels_\n",
    "        df_labels[str(k)] = y_pred\n",
    "\n",
    "        if k == 1:\n",
    "            silhouette = np.nan\n",
    "        else:\n",
    "            silhouette = silhouette_score(proj_X, y_pred)\n",
    "        silhouette_list.append(silhouette)\n",
    "\n",
    "\n",
    "    metric_dictionary = {\n",
    "                         'Silhouette': silhouette_list,\n",
    "                         'Eigengap': eigenvals_sorted,\n",
    "                        }\n",
    "    \n",
    "    if(plot):\n",
    "        plot_metrics(n_clusters_list, metric_dictionary)\n",
    "        return df_labels\n",
    "    else:\n",
    "        return df_labels, metric_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e045e0-da50-4336-8879-02cc37e2c1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = []\n",
    "send(cluster_labels, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
